[
    % TODO this is needed to deploy oneprovider on distributed env on dockers
    % Range of ports that will be used by erlang nodes to communicate
    {kernel, [
        {inet_dist_listen_min, 9100},
        {inet_dist_listen_max, 9139}
    ]},

    %% SASL config
    {sasl, [{sasl_error_logger, false}]},

    %% logger configuration
    {lager, [
        {colored, true},
        {handlers, [
            %% show info level or higher level logs at console
            {lager_console_backend, [
                {level, info}, {formatter, lager_default_formatter},
                {formatter_config, [color, "[", sev, " ", time, " ", pid, "] ", message, "\e[0m\r\n"]}
            ]},
            %% rotate error log when it reaches 50 MB; keep 10 rotated logs
            {lager_file_backend, [
                {file, "{{platform_log_dir}}/error.log"},
                {level, error},
                {size, 52428800},
                {count, 10},
                {formatter, lager_default_formatter},
                {formatter_config, ["[", sev, " ", date, " ", time, " ", pid, "] ", message, "\n"]}
            ]},
            %% rotate info log when it reaches 50 MB; keep 10 rotated logs
            {lager_file_backend, [
                {file, "{{platform_log_dir}}/info.log"},
                {level, info},
                {size, 52428800},
                {count, 10},
                {formatter, lager_default_formatter},
                {formatter_config, ["[", sev, " ", date, " ", time, " ", pid, "] ", message, "\n"]}
            ]},
            %% rotate debug log when it reaches 50 MB; keep 10 rotated logs
            {lager_file_backend, [
                {file, "{{platform_log_dir}}/debug.log"},
                {level, debug},
                {size, 52428800},
                {count, 10},
                {formatter, lager_default_formatter},
                {formatter_config, ["[", sev, " ", date, " ", time, " ", pid, "] ", message, "\n"]}
            ]}
        ]},
        % Limit for the number of messages per second allowed from error_logger
        {error_logger_hwm, 200},
        % When lager should change mode to synchronous (log queue is longer than async_threshold)
        {async_threshold, 500},
        % When lager should return from synchronous mode to asynchronous (log queue is shorter than (async_threshold - async_threshold_window)
        {async_threshold_window, 50}
    ]},

    %% mnesia config
    {mnesia, [
        {dump_log_write_threshold, 50000}
    ]},

    {ctool, [
        % Path to the JSON file holding information about services compatibility
        % and verified gui hashes. This file evolves during service's lifetime -
        % can be overwritten by a newer registry when such is available.
        {compatibility_registry_path, "{{platform_etc_dir}}/compatibility.json"},
        % Path to the default compatibility.json for current software version.
        {default_compatibility_registry, "{{platform_data_dir}}/compatibility.default.json"}
    ]},

    %% cluster_worker config
    {cluster_worker, [

        % Exometer settings
        {exometer_lager_reporter, false},
        {exometer_data_points_number, 100},

        %% External IP of this node - used by DNS and for inter-provider communication
        %% can be set to a tuple or string, for example:
        %% {external_ip, {10,0,0,1}}, or:
        %% {external_ip, "10.0.0.1"},
        {external_ip, undefined},

        %% ===================================================================
        %% Garbage collection
        %% ===================================================================

        % Should couchbase pool force garbage collection (options: on, off)
        {couchbase_pool_gc, off},
        % Should tp force garbage collection (options: on, off)
        {tp_gc, off},

        %% ===================================================================
        %% PLUGINS
        %% ===================================================================

        % names of modules implementing given plugins
        {datastore_config_plugin, datastore_config_plugin},
        {node_manager_plugin, node_manager_plugin},

        % Number of tp subtrees
        % (tree of tp_servers is divided into several subtrees)
        {tp_subtrees_number, 20},
        % Enable handling of link and doc calls in single tp proc
        {aggregate_tp, true},
        % Size of tp key space (0 - unlimited)
        {tp_space_size, 2000},

        {datastore_cache_size, [
            {memory, 50000},
            {disc, 50000}
        ]},

        {couchbase_durability_interval, 500},
        {couchbase_pool_size, [
            {'_', [
                {read, 5},
                {write, 20},
                {changes, 3}
            ]}
        ]},
        {couchbase_pool_batch_size, 1000},
        {couchbase_pool_max_batch_size, 2000},
        {couchbase_pool_min_batch_size, 500},

        % Throttlers configuration
        % % Each parameter has 3 config values:
        % - expected - expected value of parameter
        %       (no throttling for lower values),
        % - limit - requests are blocked when limit is reached,
        % - strength (higher strength results in higher delay when
        %       expected value is exceeded).
        % There are 6 parameters:
        % - tp_proc - max number of tp processes in tp subtree,
        % - db_queue_max - max number of documents in db queue,
        % - flush_queue - number of documents in couchbase disk write queue,
        % - db_queue_sum - sum of numbers of documents in all db queue +
        %       number of documents in couchbase disk write queue +
        %       number of documents waiting to be flushed in tp processes,
        % - tp_size - number of documents waiting to be flushed in tp processes,
        % - memory - memory usage in percent.
        {throttling_config, [
            {import, [
                {base_time_ms, 40960},
                {strength, 50},
                {db_queue_max_expected, 4000},
                {tp_size_sum_expected, 30000}
            ]},
            {default, [
                {base_time_ms, 40960},
                {strength, 20},
                {tp_param_strength, 1},
                {db_max_param_strength, 1},
                {flush_queue_param_strength, 1},
                {db_sum_param_strength, 0},
                {tp_size_sum_param_strength, 1},
                {mem_param_strength, 0},
                {tp_proc_expected, 20000},
                {tp_proc_limit, 40000},
                {db_queue_max_expected, 8000},
                {db_queue_max_limit, 20000},
                {db_flush_queue_expected, 200000},
                {db_flush_queue_limit, 500000},
                {db_queue_sum_expected, 40000},
                {db_queue_sum_limit, 100000},
                {tp_size_sum_expected, 500000},
                {tp_size_sum_limit, 1000000},
                {memory_expected, 90},
                {memory_limit, 95}
            ]}
        ]},

        %% Number of tp processes to reduce tp process idle time
        {throttling_reduce_idle_time_memory_proc_number, 2000},
        {throttling_min_idle_time_memory_proc_number, 10000},

        %% ===================================================================
        %% Logs
        %% ===================================================================

        {monitoring_log_file, "{{platform_log_dir}}/node_manager_monitoring.log"},
        {throttling_log_file, "{{platform_log_dir}}/throttling_monitoring.log"},

        {monitoring_log_file_max_size, 52428800}, % 50 MB
        {throttling_log_file_max_size, 52428800},  % 50 MB

        %% ===================================================================
        %% Graphite config
        %% ===================================================================

        {counter_name_prefixes, [comp, op_worker]},

        %% Should graphite reporter be active and namespaces used
        {integrate_with_graphite, false},
        %% address of graphite db
        {graphite_host, "172.17.0.2"},
        %% graphite port
        {graphite_port, 2003},
        %% api key for graphite
        {graphite_api_key, <<"example_key">>},
        %% graphite metrics prefix
        {graphite_prefix, <<"onedata">>},
        %% graphite connection timeout
        {graphite_connect_timeout, 5000},

        %% ===================================================================
        %% ls config
        %% ===================================================================

        %% Should cache fold link token be cached by cache writer
        %% Warning: other possibility is use cache_list_dir_token flag - do not use both
        {cache_fold_token, true},
        %% Time of fold link token caching by cache writer
        {fold_cache_timeout, 30000}
    ]},

    %% op_worker config
    {op_worker, [
        %% ===================================================================
        %% Garbage collection
        %% ===================================================================

        % Should dbsync_in_stream force garbage collection (options: on, off)
        {dbsync_in_stream_gc, off},
        % Should dbsync_in_stream_worker force garbage collection (options: on, off)
        {dbsync_in_stream_worker_gc, off},
        % Should dbsync_out_stream force garbage collection (options: on, off)
        {dbsync_out_stream_gc, off},
        % Should replica_synchronizer force garbage collection
        % (options: on_flush_location, on_flush_stats, on_flush_blocks, off)
        {synchronizer_gc, on_flush_location},
        % Should transfer_onf_stats_aggregator force garbage collection
        % (options: on, off)
        {transfer_onf_stats_aggregator_gc, off},

        %% ===================================================================
        %% PORTS
        %% ===================================================================

        %% Port on which HTTPS server is started
        {https_server_port, 443},
        %% Port on which HTTP server is started
        {http_server_port, 80},
        %% OZ REST API port
        {oz_rest_port, 443},
        %% Port number in Onezone where Graph Sync server is hosted
        {graph_sync_port, 443},


        %% ===================================================================
        %% GENERAL
        %% ===================================================================

        %% List of possible cluster manager nodes - configured automatically by configurator.erl lib, used in GEN_DEV script
        {cm_nodes, ['cm@127.0.0.1']},
        %% List of all DBMS nodes - configured automatically by configurator.erl lib, used in GEN_DEV script
        {db_nodes, ['127.0.0.1:49161']},

        % Build version in form:
        % <number of commits since last tag>-g<last commit hash abbrev>
        % e.g. 19-g0d0fd5b
        {build_version, "{{{build_version}}}"},

        %% ===================================================================
        %% Server certificates
        %% ===================================================================

        %% NOTE: below envs are overwritten by onepanel during deployment. You
        %% should always use onepanel to manage web certs, unless you really
        %% know what you are doing.
        %% Path to private key used by web server
        {web_key_file, "{{platform_etc_dir}}/certs/web_key.pem"},
        %% Path to certificate used by web server
        {web_cert_file, "{{platform_etc_dir}}/certs/web_cert.pem"},
        %% Path to certificate chain file used by web server
        {web_cert_chain_file, "{{platform_etc_dir}}/certs/web_chain.pem"},


        %% Path to directory with trusted CA certificates
        {cacerts_dir, "{{platform_etc_dir}}/cacerts"},

        %% Set level of security for inter-provider connections. Possible values:
        %%      true - provider's web certificate is checked against known CA's and
        %%          its domain is verified (cert must be issued for that domain).
        %%      only_verify_peercert - provider's web certificate is checked against
        %%          known CA's, but its domain is ignored - useful when providers do
        %%          not have assigned domains and use IP addresses, but less safe.
        %%      false - no security checks are performed, which creates a risk
        %%          of provider impersonation - use with care!
        {interprovider_connections_security, true},

        %% Path where Oneprovider's root token and id will be stored for
        %% offline access.
        %% When changing this variable, take care to regenerate
        %% op_worker_root_token_path variable's value in onepanel config.
        {root_token_path, "{{platform_etc_dir}}/provider_root_token.json"},

        %% ===================================================================
        %% Provider protocol
        %% ===================================================================

        %% Number of acceptors for protocol listener
        {protocol_handler_pool_size, 100},
        %% How long resolved provider nodes are cached
        {provider_nodes_cache_ttl, 600000},  % 10 minutes

        %% ===================================================================
        %% HTTP & HTTPS servers config
        %% ===================================================================

        %% Number of accepting processes in the listeners
        {http_acceptors, 10},
        {https_acceptors, 100},
        %% Request timeout in milliseconds, meaning how long the server should
        %% wait for an incoming request since the last activity until it closes
        %% the connection.
        {http_request_timeout, 30000},
        {https_request_timeout, 30000},
        %% Maximum number of HTTP requests without closing the connection
        %% (HTTP/1.1 only)
        {https_max_keepalive, 30},

        %% Prefix to the REST API - all paths must begin with it.
        %% Must begin with slash
        {op_rest_api_prefix, "/api/v3/oneprovider"},

        %% Timeout when waiting for response from Onepanel -
        %% concerns proxying requests to Onepanel via Oneprovider.
        {onepanel_proxy_recv_timeout_sec, 30},

        %% ===================================================================
        %% GUI config
        %% ===================================================================

        %% Path to packaged GUI static files that will be uploaded to Onezone.
        {gui_package_path, "{{platform_data_dir}}/gui_static.tar.gz"},

        %% Buffer size used to send files to a web client, in bytes.
        {gui_download_buffer, 4194304}, % 4MB
        %% How many files will be displayed in gui data browser at once.
        %% If there are more files in the directory, they will be downloaded
        %% on demand when the user scrolls down near the bottom of the list.
        {gui_file_children_chunk_size, 50},
        %% Maximum number of async processes that may be spawned to process
        %% a batch websocket request.
        {gui_max_async_processes_per_batch, 10},
        % This option sets default time interval between sending ping frames
        % by websocket server (op_gui_ws_handler).
        {gui_websocket_keepalive, 30000},

        %% Time of inactivity (no bytes sent), in seconds, before removing
        %% connection between providers on space transfers map.
        {gui_transfer_inactivity_treshold, 20},
        %% Time (in ms) for which space transfers minute stats are cached.
        {gui_transfer_min_stat_expiration, 5000},
        %% Time (in ms) for which space transfers hour stats are cached.
        {gui_transfer_hour_stat_expiration, 10000},
        %% Time (in ms) for which space transfers day stats are cached.
        {gui_transfer_day_stat_expiration, 60000},
        %% Time (in ms) for which space transfers month stats are cached.
        {gui_transfer_month_stat_expiration, 300000},

        %% ===================================================================
        %% FILE UPLOAD
        %% ===================================================================

        %% Maximum timeout after which body read from request is passed to
        %% upload handler process. Note that the body is returned immediately
        %% if its size reaches the buffer size (upload_write_size).
        {upload_read_period, 5000},
        %% Timeout for reading upload_read_size bytes from socket.
        {upload_read_timeout, 300000},
        %% How many bytes will be written to filesystem at once during upload.
        %% Such chunk will be accumulated using
        %% multiple reads of upload_read_size.
        {upload_write_size, 1000000},

        %% ===================================================================
        %% CDMI
        %% ===================================================================

        %% Size of download buffer. Currently set to 8MB.
        {download_buffer_size, 8388608},
        %% Maximum amount of directory children that can be requested in one request
        {max_children_per_request, 1000},

        %% ===================================================================
        %% SEQUENCER_MANAGER
        %% ===================================================================

        %% Maximal amount of messages that can be forwarded by sequencer
        %% stream between successive emissions of acknowledgement messages.
        {sequencer_stream_msg_ack_threshold, 100},
        %% Amount of seconds that have to elapse before sending next request
        %% when waiting for missing messages.
        {sequencer_stream_msg_req_short_timeout_seconds, 1},
        %% Amount of seconds that have to elapse before sending next request
        %% when not waiting for missing messages.
        {sequencer_stream_msg_req_long_timeout_seconds, 10},

        %% ===================================================================
        %% INCOMING SESSION_WATCHER
        %% ===================================================================

        %% Maximal period of GUI session inactivity before removal
        {gui_session_grace_period_seconds, 300},
        %% Maximal period of FUSE session inactivity before removal
        {fuse_session_grace_period_seconds, 300},
        %% Maximal period of REST session inactivity before removal
        {rest_session_grace_period_seconds, 300},
        %% Maximal period of Provider's session inactivity before removal
        {provider_session_grace_period_seconds, 3600},

        %% Interval between token_credentials() checks. Those checks are necessary as tokens
        %% can become invalid before their expiration (e.g. can be revoked)
        {session_validity_check_interval_seconds, 15},

        %% ===================================================================
        %% OZ INTERFACING
        %% ===================================================================

        %% OZ hostname
        {oz_domain, undefined}, % will be overridden by Onepanel
        %% OZ login page (relative to domain)
        {oz_login_page, "/#/home/login"},
        %% OZ logout page (relative to domain)
        {oz_logout_page, "/logout"},
        %% OZ manage providers page (relative to domain)
        {oz_providers_page, "/#/onedata/providers/not-selected"},
        %% OZ REST API prefix
        {oz_rest_api_prefix, "/api/v3/onezone"},
        %% Tokens used by provider will be confined to this TTL for security
        {provider_token_ttl_sec, 900},
        %% Authorization nonces generated by provider
        %% will have this TTL for security
        {provider_authorization_nonce_ttl_sec, 30},
        %% Interval between consecutive sync progress stats reports sent to Onezone
        {provider_sync_progress_report_interval_sec, 15},

        %% REST route needed for Let's Encrypt challenge responses
        {letsencrypt_challenge_api_prefix, "/.well-known/acme-challenge"},
        %% Static content root needed for Let's Encrypt challenge responses
        {letsencrypt_challenge_static_root, "/tmp/op_worker/http/.well-known/acme-challenge/"},

        %% ===================================================================
        %% AUTH CACHE (cache storing user auths verified by oz)
        %% ===================================================================

        %% Max size of auth cache
        {auth_cache_size_limit, 5000},
        %% Time (in milliseconds), after disconnecting from Onezone, during
        %% which auth cache entries will still be served
        {auth_cache_purge_delay, 300000},
        %% Interval (in milliseconds) between checks of auth cache size
        {auth_cache_size_check_interval, 2000},
        %% Default time (in seconds) for which cache entries will be considered
        %% valid and served from cache
        {auth_cache_item_default_ttl, 10},

        %% ===================================================================
        %% FSLOGIC
        %% ===================================================================

        %% Events configuration
        {file_read_event_time_threshold_milliseconds, 1000},
        {file_written_event_time_threshold_milliseconds, 1000},

        %% Default values
        {default_dir_mode, 8#775},
        {default_file_mode, 8#664},

        %% Default number of listed children in lfm:get_children_count
        {ls_chunk_size, 5000},

        %% Default size of file content chunk copied at once in rename_req
        {rename_file_chunk_size, 8388608}, %% 8MB

        %% Max number of processes that are used to handle read_dir_plus request
        {max_read_dir_plus_procs, 20},
        %% Delay in blocks flush by replica synchronizer
        {blocks_flush_delay, 10000},
        % Min size of replicated block to be published
        {public_block_size_treshold, 12582912}, % 12 MB
        % Min size (in percent of file's size) of replicated block to be published
        {public_block_percent_treshold, 10},
        % Type of store of local blocks
        % Possible values: doc, links, none
        {local_blocks_store, doc},
        % Local blocks flush
        % Possible values: on_terminate, always
        {local_blocks_flush, on_terminate},
        % Max size of document that stores local blocks
        {blocks_doc_max_size, 50000},

        %% ===================================================================
        %% EVENTS
        %% ===================================================================

        %% Max retries to send event to stream
        {event_manager_retries, 1},
        %% Should log errors during sending events to stream
        {log_event_manager_errors, false},

        %% ===================================================================
        %% CONNECTION
        %% ===================================================================

        %% Sockets mode used when creating sockets. Possible values are active_once
        %% and active_always. They behave exactly as described in official documentation
        {default_socket_mode, active_always},
        %% Flag telling whether to verify msg correctness (e.g. types) or not
        %% before encoding
        {verify_msg_before_encoding, false},
        %% Flag telling whether to log whole messages or only relevant info
        {log_whole_messages_on_errors, false},

        %% ===================================================================
        %% RTRANSFER
        %% ===================================================================
        %% Tells if rtransfer should be started on fslogic_worker init
        {start_rtransfer_on_init, true},
        %% Possible values - sync, async, off
        {force_rtransfer_gc, async},
        %% How many simultaneous operations can be performed per gateway_connection
        {gateway_connection_load_factor, 1},
        %% Default rtransfer_block_size
        %% Warning: gateway_connection_load_factor * rtransfer_block_size
        %% should be less than half of +hmax option in vm.args.template,
        {rtransfer_block_size, 26214400}, % 25 MB
        %% How long (in ms) transferred file blocks are aggregated before
        %% updating location docs
        {rtransfer_blocks_aggregation_time, 1000},
        %% How long (in ms) transfer stats are aggregated before updating
        %% transfer document
        {rtransfer_stats_aggregation_time, 1000},
        %% How long (in ms) stats for on the fly transfers are aggregated
        %% before updating space_transfer_stats document
        {onf_transfer_stats_aggregation_time, 4500},
        % Min size of hole in transfer
        {rtransfer_min_hole_size, 2097152}, % 2MB
        % Events about not finished transfers (with id and on the fly)
        % flush by synchronizer
        % possible values: all, off, transfers_only
        {synchronizer_in_progress_events, transfers_only},
        % Events about finished transfers (with id) flush by synchronizer
        % possible values: all, off, {threshold, Bytes}
        {synchronizer_transfer_finished_events, all}, % 4MB
        % Events about finished transfers (on the fly) flush by synchronizer
        % possible values: all, off, {threshold, Bytes}
        {synchronizer_on_fly_finished_events, {threshold, 4194304}}, % 4MB
        % Mock rtransfer - makes all transfers succeed without actually
        % transmitting data
        {rtransfer_mock, false},

        %% ===================================================================
        %% HELPERS
        %% ===================================================================

        %% Default timeout for the storage helper asynchronous operation
        {helpers_async_operation_timeout_milliseconds, 300000},
        %% Max latency for the proxy helper operations
        {proxy_helper_latency_milliseconds, 5000},
        %% Number of parallel POSIX helper threads.
        {posix_helper_threads_number, 8},
        %% Number of parallel Ceph helper threads.
        {ceph_helper_threads_number, 8},
        %% Number of parallel CephRados helper threads.
        {cephrados_helper_threads_number, 8},
        %% Number of parallel S3 helper threads.
        {s3_helper_threads_number, 8},
        %% Number of parallel Swift helper threads.
        {swift_helper_threads_number, 8},
        %% Number of parallel GlusterFS helper threads.
        {glusterfs_helper_threads_number, 8},
        %% Number of parallel WebDAV helper threads.
        {webdav_helper_threads_number, 25},
        %% Number of parallel Null Device helper threads.
        {nulldevice_helper_threads_number, 8},
        %% Defines whether buffer storage helpers read/write operations.
        {buffer_helpers, false},
        %% Number of parallel buffer scheduler threads.
        {buffer_scheduler_threads_number, 1},
        %% Minimum size in bytes of in-memory cache for input data blocks.
        {read_buffer_min_size, 5242880}, % 5MB
        %% Maximum size in bytes of in-memory cache for input data blocks.
        {read_buffer_max_size, 10485760}, % 10MB
        %% Read ahead period in seconds of in-memory cache for input data blocks.
        {read_buffer_prefetch_duration, 1}, % 1s
        %% Minimum size in bytes of in-memory cache for output data blocks.
        {write_buffer_min_size, 20971520}, % 20MB
        %% Maximum size in bytes of in-memory cache for output data blocks.
        {write_buffer_max_size, 52428800}, % 50MB
        %% Idle period in seconds before flush of in-memory cache for output data blocks.
        {write_buffer_flush_delay, 5}, % 5s

        %% ===================================================================
        %% HELPERS PERFORMANCE MONITORING
        %% ===================================================================

        %% Performance monitoring enable flag.
        {helpers_performance_monitoring_enabled, false},
        %% Performance monitoring type, currently only 'graphite' is supported.
        {helpers_performance_monitoring_type, "graphite"},
        %% Performance monitoring level, either 'basic' or 'full'. Basic mode reports
        %% raw counter and timer values, while full reports precomputed averages, rates and
        %% throughputs.
        {helpers_performance_monitoring_level, "full"},
        %% Performance monitoring reporting period, in seconds.
        {helpers_performance_monitoring_period, 30},

        %% ===================================================================
        %% LUMA
        %% ===================================================================

        %% User/Group storage ID mapping boundaries
        {luma_posix_uid_range, {100000, 2000000}},
        {luma_posix_gid_range, {100000, 2000000}},

        %% ===================================================================
        %% PREFETCHING
        %% ===================================================================

        %% Sync requests which are smaller will be extended to 1MB
        {minimal_sync_request, 1048576},
        %% Synchronization of byte 0, 50MB, 100MB etc. will trigger prefetching
        {trigger_byte, 52428800},
        %% Amount of data to prefetch at once
        {prefetch_size, 104857600},

        %% ===================================================================
        %% MONITORING
        %% ===================================================================

        %% Size of worker pool for rrdtool
        {rrdtool_pool_size, 10},
        %% Maximum size of worker pool overflow for rrdtool
        {rrdtool_pool_max_overflow, 10},

        %% ===================================================================
        %% STORAGE SYNC
        %% ===================================================================
        %% How often does storage_sync_worker checks whether storage_sync scan
        %% should be started in synced spaces
        {storage_sync_check_interval, 10},  % seconds
        % Number of workers that will handle storage_sync dir jobs
        {storage_sync_master_jobs_limit, 10},
        % Number of workers that will handle storage_sync file jobs
        {storage_sync_slave_workers_limit, 10},
        % Maximum number of spaces that can be processed by storage_sync_traverse
        % pool in parallel
        {storage_sync_parallel_synced_spaces_limit, 10},
        % Size of batch of files listed during syncing storage
        {storage_sync_dir_batch_size, 1000},
        % Number of time slots from which monitoring data is saved
        {storage_sync_histogram_length, 12},
        % storage_sync audit log file prefix, it will be appended with
        % space id followed by storage_sync_audit_log_file_extension
        {storage_sync_audit_log_file_prefix, "{{platform_log_dir}}/storage_sync_"},
        {storage_sync_audit_log_file_extension, ".log"},

        %% ===================================================================
        %% TRANSFER JOBS
        %% ===================================================================
        %% Number of workers that will be responsible for replicating files
        {replication_workers_num, 50},
        %% Number of workers that will be responsible for controlling transfers
        %% this value is an upper limit for number of simultaneous incoming
        %% transfers
        {replication_controllers_num, 10},
        %% Number of workers that will be responsible for traversing directories
        %% and scheduling replica evictions
        {replica_eviction_workers_num, 10},
        %% Acceptable number of transfer retries per file
        {max_file_replication_retries_per_file, 0},
        %% Acceptable number of eviction retries per file
        {max_eviction_retries_per_file_replica, 0},
        %% Acceptable number of failed file transfers per whole transfer
        %% NOTE: file transfer is considered failed when
        %% max_file_replication_retries_per_file or
        %% max_eviction_retries_per_file_replica number is exceeded
        %% for given file
        {max_file_transfer_failures_per_transfer, 10},
        %% Limit of the number of transfers that are remembered in history per file.
        {transfers_history_limit_per_file, 100},
        %% Batch size which will be used to iterate over view to schedule replication
        {replication_by_view_batch, 1000},
        %% Batch size which will be used to iterate over view to schedule
        %% replica eviction
        {replica_eviction_by_view_batch, 1000},

        %% ===================================================================
        %% REPLICA DELETION
        %% ===================================================================
        %% Number of workers that will be responsible for deleting file replicas from storage
        {replica_deletion_workers_num, 10},
        %% Maximum number of currently handled deletion requests by
        %% replica_deletion_master
        {replica_deletion_max_parallel_requests, 10000},

        %% ===================================================================
        %% GRAPH SYNC
        %% ===================================================================
        %% HTTP path where Graph Sync websocket client should connect
        {graph_sync_path, "/graph_sync/provider"},
        %% Maximum time to wait for response from OZ before returning timeout error.
        {graph_sync_request_timeout, 30000}, % 30 seconds
        %% Timeout for metadata harvest requests (that typically are much longer).
        {graph_sync_harvest_metadata_request_timeout, 120000}, % 120 seconds
        %% How often Graph Sync channel is health-checked
        {graph_sync_healthcheck_interval, 4000},
        %% How often Graph Sync performs a keepalive request
        {graph_sync_keepalive_interval, 30000},
        %% Rate of reconnect attempt delay increase for Graph Sync channel.
        {graph_sync_reconnect_backoff_rate, 1.5},
        %% Maximum delay between reconnect attempts for Graph Sync channel.
        {graph_sync_reconnect_max_backoff, 300000}, % 5 minutes

        %% ===================================================================
        %% DBSYNC
        %% ===================================================================

        %% Min size of parallel batch used during changes apply
        {dbsync_changes_apply_min_group_size, 10},
        %% Batch size using during changes broadcasting
        {dbsync_changes_broadcast_batch_size, 100},
        %% Min batch size to spawn handler
        {dbsync_handler_spawn_size, 10},
        %% Max number of changes applied in parallel
        {dbsync_changes_apply_max_size, 500},

        %% ===================================================================
        %% WORKERS
        %% ===================================================================
        {disabled_workers, [monitoring_worker]},

        %% ===================================================================
        %% ls config
        %% ===================================================================

        %% Should cache token used during dir listing in dedicated process
        %% Warning: other possibility is use cache_fold_token flag - do not use both
        {cache_list_dir_token, false},
        %% Time of fold link token caching by cache writer
        {list_dir_token_cache_timeout, 30000},

        %% ===================================================================
        %% auto-cleaning config
        %% ===================================================================
        % flag that informs whether periodical auto-cleaning checks should be scheduled
        % in all spaces with enabled auto-cleaning mechanism
        {autocleaning_periodical_spaces_check_enabled, true},
        % interval between subsequent auto-cleaning checks
        {autocleaning_periodical_spaces_check_interval, 60000}, % 1 min,
        {autocleaning_check_interval, 10000},
        {autocleaning_view_batch_size, 1000},
        {autocleaning_master_jobs_num, 10},
        {autocleaning_slave_jobs_num, 50},
        {autocleaning_parallel_orders_limit, 10},

        %% ===================================================================
        %% file-popularity config
        %% ===================================================================
        % default weight of last_open_hour parameter of file entry in the file-popularity view
        {default_last_open_hour_weight, 1.0},
        % default weight of avg_open_count_per_day_weight parameter of file entry in the file-popularity view
        {default_avg_open_count_per_day_weight, 20.0},
        % default limit for avg_open_count_per_day parameter for file-popularity function
        % files that have avg_open_count_per_day greater or equal to given limit will be treated equally
        {default_max_avg_open_count_per_day, 100},

        %% ===================================================================
        %% HARVESTING
        %% ===================================================================
        % minimal backoff interval for harvesting_stream
        {harvesting_stream_min_backoff_interval, 5000}, % 5 s
        % maximal backoff interval for harvesting_stream
        {harvesting_stream_max_backoff_interval, 300000}, % 5 min

        %% ===================================================================
        %% QOS
        %% ===================================================================
        {qos_traverse_master_jobs_limit, 10},
        {qos_traverse_slave_jobs_limit, 20},
        {qos_traverse_parallelism_limit, 5},
        {qos_traverse_batch_size, 40},

        {qos_bounded_cache_check_frequency, 300000}, % 5 min
        {qos_bounded_cache_size, 15000},

        %% ===================================================================
        %% STORAGE TRAVERSE
        %% ===================================================================
        {storage_traverse_batch_size, 100},
    
        %% ===================================================================
        %% SPACE UNSUPPORT
        %% ===================================================================
        {space_unsupport_master_jobs_limit, 1},
        {space_unsupport_slave_jobs_limit, 5},
        {space_unsupport_parallelism_limit, 5},
        
        {unsupport_cleanup_traverse_master_jobs_limit, 10},
        {unsupport_cleanup_traverse_slave_jobs_limit, 20},
        {unsupport_cleanup_traverse_parallelism_limit, 20},
        {unsupport_cleanup_traverse_batch_size, 40}
    ]},

    {rtransfer_link, [
        {logdir, "{{platform_log_dir}}"},
        {verbosity, 0},
        {helper_workers, 100},
        {transfer, [
            %% Port on which rtransfer is available
            {server_port, 6665},
            %% Number of parallel rtransfer streams between providers
            {data_conns_per_link, 16},
            %% Max byte size of a single transferred block (bigger blocks will be split)
            {block_size, 12582912},
            %% Byte size of socket's receive buffer
            {recv_buffer_size, 8388608},
            %% Byte size of socket's send buffer
            {send_buffer_size, 8388608},
            {max_incoming_buffered_size, 20971520},
            {storage_buckets, 100},
            {throughput_probe_interval, 25},
            {send_congestion_flavor, "bbr"}
        ]},
        {shaper, [
            %% Initial size of byte window for transfers between two storages
            {cubic_initial_window, 104857600},
            %% The maximum shaper window increase per second
            {max_increase, 10485760},
            %% If every storage read/write delay is the last codel_period is bigger
            %% than the codel_target_delay, the storage is considered overloaded
            {codel_target_delay, 1000},
            {quantum_ms_size, 50}
        ]}
    ]}
].
